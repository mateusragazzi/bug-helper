{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "completando dataset 3 - issues 20 years Mozilla 2020.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tjRmnDUkjkkg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateusragazzi/bug-helper/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjRmnDUkjkkg"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xUGRnXajIXJ",
        "outputId": "2f28bbfb-dd5f-4b76-a86a-7ddbd8a25132"
      },
      "source": [
        "!pip install fastparquet\n",
        "!pip install python-Levenshtein\n",
        "#!pip install textblob\n",
        "#!python -m textblob.download_corpora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastparquet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/3e/970dcb3605c1d406be9304f00895bf89ca6b71162afa7f95c5a4032bf927/fastparquet-0.5.0.tar.gz (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.1.5)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.19.5)\n",
            "Collecting thrift>=0.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/1e/3284d19d7be99305eda145b8aa46b0c33244e4a496ec66440dac19f8274d/thrift-0.13.0.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->fastparquet) (54.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->fastparquet) (0.34.0)\n",
            "Requirement already satisfied: six>=1.7.2 in /usr/local/lib/python3.7/dist-packages (from thrift>=0.11.0->fastparquet) (1.15.0)\n",
            "Building wheels for collected packages: fastparquet, thrift\n",
            "  Building wheel for fastparquet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastparquet: filename=fastparquet-0.5.0-cp37-cp37m-linux_x86_64.whl size=213353 sha256=cb9eb0f94cd5f28c641d449439e41baf34061db016ec2e35bcff8cde5e895054\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/0e/da/e2122965947ab2bfbc20e31a968e998fc8932f7fcb0ed78ad0\n",
            "  Building wheel for thrift (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thrift: filename=thrift-0.13.0-cp37-cp37m-linux_x86_64.whl size=348151 sha256=746741f239910004ec287f6061e3fe4492bbb5a2e6cbe1f25553007565d91266\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/a2/46/689ccfcf40155c23edc7cdbd9de488611c8fdf49ff34b1706e\n",
            "Successfully built fastparquet thrift\n",
            "Installing collected packages: thrift, fastparquet\n",
            "Successfully installed fastparquet-0.5.0 thrift-0.13.0\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (54.0.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149810 sha256=938991dea7749cefc241f55a81d9f23866c73d7863f000b3699f819d094de25f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eNs7Suw9X7H"
      },
      "source": [
        "##### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMvddI009axx",
        "outputId": "1fbc7fb3-1607-4b1f-bfcf-db9db721d85e"
      },
      "source": [
        "from fastparquet import ParquetFile\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import Levenshtein\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('tagsets')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WH6nvtUjwDV"
      },
      "source": [
        "### Main Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7TYtinwm3ge"
      },
      "source": [
        "#### Read `.parquet` file, converting it to pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0dHQfi8gvDZ"
      },
      "source": [
        "\n",
        "parquetFile = ParquetFile('drive/MyDrive/Colab/issues.parquet', verify=True)\n",
        "pandasDataFrame = parquetFile.to_pandas()\n",
        "\n",
        "# Filter only bugs\n",
        "bugDataFrame = pandasDataFrame[pandasDataFrame[\"issuetype\"].str.contains(\"Bug\", na=False)]\n",
        "# Filter except bugs\n",
        "baseDataFrame = pandasDataFrame[~pandasDataFrame[\"issuetype\"].str.contains(\"Bug\", na=False)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xSIk-Ge1PRB5",
        "outputId": "6289ac8f-5fc3-4cad-895c-7e0ef36233f8"
      },
      "source": [
        "baseDataFrame.loc[2314123]['summary']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'When a website requests VR access, Firefox Nightly puts up a link to a non-existant page'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCnid-CLbqwt"
      },
      "source": [
        "#### Get one item from bug to analise and clean phrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVBguEQrIg84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6d06c0-c3f9-4b48-d34a-320942bb9d1d"
      },
      "source": [
        "def clean_string(text):\n",
        "  if (text is not None):\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
        "    text = ''.join([word for word in text if word not in string.punctuation])\n",
        "    text = text.lower()\n",
        "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "    return text\n",
        "  else:\n",
        "    return \"\"\n",
        "\n",
        "# focusedItem = bugDataFrame.loc[202]['summary']\n",
        "focusedItem = \"When a website requests VR access, Firefox Nightly puts up a link to a non-existant page\"\n",
        "focusedItem = clean_string(focusedItem)\n",
        "\n",
        "print(focusedItem)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "when website requests vr access firefox nightly puts link nonexistant page\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eEmz3wYEvyZ"
      },
      "source": [
        "#### Search the closest item inside base dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mAUz8uYqOBf",
        "outputId": "7d30593e-844f-41c8-c441-8f681f5a7c53"
      },
      "source": [
        "minDistance = 0;\n",
        "betterIndex = 0;\n",
        "\n",
        "for index, row in baseDataFrame.iterrows():\n",
        "  phrase = clean_string(row['summary'])\n",
        "  distance = Levenshtein.distance(focusedItem, phrase)\n",
        "  if (minDistance == 0):\n",
        "    minDistance = distance\n",
        "    betterIndex = index\n",
        "  elif (distance < minDistance) :\n",
        "    minDistance = distance\n",
        "    betterIndex = index\n",
        "\n",
        "print(\"better index: \", betterIndex)\n",
        "print(\"min distance: \", minDistance)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "better index:  2314124\n",
            "min distance:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyos5yRVE5-Y"
      },
      "source": [
        "#### Printing the severity and days to resolved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIJs9YzR8cHh",
        "outputId": "2c718749-9f15-4ac4-a9d8-0343491ea451"
      },
      "source": [
        "item = baseDataFrame.loc[betterIndex]\n",
        "\n",
        "severity = item['severity']\n",
        "created = item['created']\n",
        "last_resolved = item['last_resolved']\n",
        "\n",
        "resolvedTime = (str) ((last_resolved - created).days)\n",
        "\n",
        "if (resolvedTime is None):\n",
        "  resolvedTime = \"0\"\n",
        "\n",
        "if (severity is None):\n",
        "  severity = \"unknown\"\n",
        "\n",
        "print(\"Your problem has a \" + severity + \" severity and will take \" + resolvedTime + \" day(s) to resolve\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your problem has a normal severity and will take nan day(s) to resolve\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}